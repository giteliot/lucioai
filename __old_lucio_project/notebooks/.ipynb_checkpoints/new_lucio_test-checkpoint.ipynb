{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dc0ebd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.utils as torch_utils\n",
    "from torch.nn.functional import one_hot\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4dfe69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.ln1 = nn.LayerNorm(hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.ln2 = nn.LayerNorm(hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        nn.init.kaiming_uniform_(self.fc1.weight, nonlinearity='relu')\n",
    "        nn.init.kaiming_uniform_(self.fc2.weight, nonlinearity='relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.ln1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.ln2(out)\n",
    "        out = self.relu(out)    \n",
    "        out = self.fc3(out)\n",
    "        return nn.functional.softmax(out, dim=-1).squeeze()\n",
    "\n",
    "class Memory:\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "\n",
    "    def push(self, command, action, reward):\n",
    "        if len(self.memory) >= self.capacity:\n",
    "               self.memory.pop(0)\n",
    "        self.memory.append((command, action, reward))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, min(len(self.memory), batch_size))\n",
    "        if len(self.memory) < 2:\n",
    "            return []\n",
    "        if len(self.memory) >= 2*batch_size:\n",
    "            return random.sample(self.memory, batch_size)\n",
    "        return random.sample(self.memory, int(len(self.memory)/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2194f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmd_to_tensor(cmd):\n",
    "    return one_hot(torch.tensor(cmd), 4).float()\n",
    "\n",
    "def get_move(command):\n",
    "    with torch.no_grad():\n",
    "        output = model(cmd_to_tensor(command))\n",
    "        print(f\"\"\"\n",
    "        0: {model(cmd_to_tensor(0))}\n",
    "        1: {model(cmd_to_tensor(1))}\n",
    "        2: {model(cmd_to_tensor(2))}\n",
    "        3: {model(cmd_to_tensor(3))}\n",
    "        \"\"\")\n",
    "        return torch.multinomial(output, 1).item()\n",
    "    \n",
    "def _get_reward_and_lr(move, model_output, good):\n",
    "    p = model_output[move]\n",
    "    \n",
    "    if p > 0.9 and good:\n",
    "        return None, None\n",
    "    # print(f\"\"\"\n",
    "    # {p}\n",
    "    # {move}\n",
    "    # {good}\n",
    "    # \"\"\")\n",
    "    min_c = 1e-6\n",
    "    max_c = 0.05\n",
    "    m = max_c-1*min_c\n",
    "    q = min_c\n",
    "    if good:\n",
    "        m = -1*m\n",
    "        q = max_c\n",
    "    lr = m*p + q\n",
    "    \n",
    "    min_c = 1\n",
    "    max_c = 10\n",
    "    if not good:\n",
    "        min_c = -10\n",
    "        max_c = -1\n",
    "    m = max_c-1*min_c\n",
    "    q = min_c\n",
    "    if good:\n",
    "        m = -1*m\n",
    "        q = max_c\n",
    "    reward = m*p + q\n",
    "    \n",
    "    # print(reward.item(), lr.item())\n",
    "    return reward.item(), lr.item()\n",
    "    return reward.item(), 0.05\n",
    "    \n",
    "def _base_train(command, move, good, is_from_memory):\n",
    "    command_t = cmd_to_tensor(command)\n",
    "    output_prob = model(command_t)\n",
    "    \n",
    "    move_t = torch.tensor(move).long()\n",
    "    if is_from_memory and output_prob[move_t]  >= 0.6:\n",
    "        return\n",
    "    \n",
    "    reward, lr = _get_reward_and_lr(move, output_prob, good)\n",
    "    if reward is None:\n",
    "        return\n",
    "    reward_t = torch.tensor(reward).float()\n",
    "    \n",
    "    \n",
    "    loss = -torch.log(output_prob[move_t])*reward_t\n",
    "    \n",
    "    for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    torch_utils.clip_grad_norm_(model.parameters(), max_norm=0.8)\n",
    "    optimizer.step()\n",
    "\n",
    "def replay_memory():\n",
    "    for command, move, reward in memory.sample(100):\n",
    "        _base_train(command, move, reward, True)\n",
    "        \n",
    "def train(command, move, good):\n",
    "    _base_train(command, move, good, False)\n",
    "    replay_memory()\n",
    "    memory.push(command, move, good)\n",
    "\n",
    "device = torch.device('cpu')\n",
    "model = Net(4, 4, 4).to(device)\n",
    "memory = Memory(100)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
    "# optimizer = optim.RMSprop(model.parameters(), lr=0.001, alpha=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b64fcd9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        0: tensor([6.4740e-01, 1.0272e-06, 3.5205e-01, 5.4929e-04])\n",
      "        1: tensor([0.0139, 0.9668, 0.0055, 0.0138])\n",
      "        2: tensor([1.6709e-02, 5.9168e-05, 9.0881e-01, 7.4421e-02])\n",
      "        3: tensor([5.6614e-06, 6.5245e-03, 1.2714e-02, 9.8076e-01])\n",
      "        \n",
      "1 -> 1\n",
      "goood\n",
      "\n",
      "        0: tensor([6.2902e-01, 1.0503e-06, 3.7037e-01, 6.0815e-04])\n",
      "        1: tensor([0.0119, 0.9693, 0.0052, 0.0136])\n",
      "        2: tensor([1.1026e-02, 7.8536e-05, 8.7985e-01, 1.0905e-01])\n",
      "        3: tensor([3.9183e-06, 6.4443e-03, 1.0002e-02, 9.8355e-01])\n",
      "        \n",
      "1 -> 1\n",
      "goood\n"
     ]
    }
   ],
   "source": [
    "train_data = [1]*2\n",
    "\n",
    "for c in train_data:\n",
    "    m = get_move(c)\n",
    "    print(f\"{c} -> {m}\")\n",
    "    reward = False\n",
    "    if m == c:\n",
    "        print(f\"goood\")\n",
    "        reward = True\n",
    "    train(c, m, reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "b93ad62e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: tensor([2.9766e-04, 7.0282e-04, 9.9840e-01, 6.0219e-04],\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "1: tensor([0.2839, 0.2210, 0.2887, 0.2063], grad_fn=<SqueezeBackward0>)\n",
      "2: tensor([0.2839, 0.2210, 0.2887, 0.2063], grad_fn=<SqueezeBackward0>)\n",
      "3: tensor([0.2839, 0.2210, 0.2887, 0.2063], grad_fn=<SqueezeBackward0>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "0: {model(cmd_to_tensor(0))}\n",
    "1: {model(cmd_to_tensor(1))}\n",
    "2: {model(cmd_to_tensor(2))}\n",
    "3: {model(cmd_to_tensor(3))}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc9da90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
