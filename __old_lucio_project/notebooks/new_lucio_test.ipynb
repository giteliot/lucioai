{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dc0ebd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.utils as torch_utils\n",
    "from torch.nn.functional import one_hot\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4dfe69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.ln1 = nn.LayerNorm(hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.ln2 = nn.LayerNorm(hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        nn.init.kaiming_uniform_(self.fc1.weight, nonlinearity='relu')\n",
    "        nn.init.kaiming_uniform_(self.fc2.weight, nonlinearity='relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.ln1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.ln2(out)\n",
    "        out = self.relu(out)    \n",
    "        out = self.fc3(out)\n",
    "        return nn.functional.softmax(out, dim=-1).squeeze()\n",
    "\n",
    "class Memory:\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "\n",
    "    def push(self, command, action, reward):\n",
    "        if len(self.memory) >= self.capacity:\n",
    "               self.memory.pop(0)\n",
    "        self.memory.append((command, action, reward))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, min(len(self.memory), batch_size))\n",
    "        if len(self.memory) < 2:\n",
    "            return []\n",
    "        if len(self.memory) >= 2*batch_size:\n",
    "            return random.sample(self.memory, batch_size)\n",
    "        return random.sample(self.memory, int(len(self.memory)/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2194f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmd_to_tensor(cmd):\n",
    "    return one_hot(torch.tensor(cmd), 4).float()\n",
    "\n",
    "def get_move(command):\n",
    "    with torch.no_grad():\n",
    "        output = model(cmd_to_tensor(command))\n",
    "        print(f\"\"\"\n",
    "        0: {model(cmd_to_tensor(0))}\n",
    "        1: {model(cmd_to_tensor(1))}\n",
    "        2: {model(cmd_to_tensor(2))}\n",
    "        3: {model(cmd_to_tensor(3))}\n",
    "        \"\"\")\n",
    "        return torch.multinomial(output, 1).item()\n",
    "    \n",
    "def _get_reward_and_lr(move, model_output, good):\n",
    "    p = model_output[move]\n",
    "    \n",
    "    if p > 0.9 and good:\n",
    "        return None, None\n",
    "    # print(f\"\"\"\n",
    "    # {p}\n",
    "    # {move}\n",
    "    # {good}\n",
    "    # \"\"\")\n",
    "    min_c = 1e-6\n",
    "    max_c = 0.05\n",
    "    m = max_c-1*min_c\n",
    "    q = min_c\n",
    "    if good:\n",
    "        m = -1*m\n",
    "        q = max_c\n",
    "    lr = m*p + q\n",
    "    \n",
    "    min_c = 1\n",
    "    max_c = 100\n",
    "    if not good:\n",
    "        min_c = -10\n",
    "        max_c = -1\n",
    "    m = max_c-1*min_c\n",
    "    q = min_c\n",
    "    if good:\n",
    "        m = -1*m\n",
    "        q = max_c\n",
    "    reward = m*p + q\n",
    "    \n",
    "    # print(reward.item(), lr.item())\n",
    "    return reward.item(), lr.item()\n",
    "    return reward.item(), 0.05\n",
    "    \n",
    "def _base_train(command, move, good, is_from_memory):\n",
    "    command_t = cmd_to_tensor(command)\n",
    "    output_prob = model(command_t)\n",
    "    \n",
    "    move_t = torch.tensor(move).long()\n",
    "    if is_from_memory and output_prob[move_t]  >= 0.6:\n",
    "        return\n",
    "    \n",
    "    reward, lr = _get_reward_and_lr(move, output_prob, good)\n",
    "    if reward is None:\n",
    "        return\n",
    "    reward_t = torch.tensor(reward).float()\n",
    "    \n",
    "    \n",
    "    loss = -torch.log(output_prob[move_t])*reward_t\n",
    "    \n",
    "    for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    torch_utils.clip_grad_norm_(model.parameters(), max_norm=0.8)\n",
    "    optimizer.step()\n",
    "\n",
    "def replay_memory():\n",
    "    for command, move, reward in memory.sample(100):\n",
    "        _base_train(command, move, reward, True)\n",
    "        \n",
    "def train(command, move, good):\n",
    "    _base_train(command, move, good, False)\n",
    "    replay_memory()\n",
    "    memory.push(command, move, good)\n",
    "\n",
    "device = torch.device('cpu')\n",
    "model = Net(4, 4, 4).to(device)\n",
    "memory = Memory(100)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=0.001, alpha=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b64fcd9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        0: tensor([0.7522, 0.0137, 0.2091, 0.0250])\n",
      "        1: tensor([0.0127, 0.7205, 0.0085, 0.2583])\n",
      "        2: tensor([0.0830, 0.0022, 0.6914, 0.2234])\n",
      "        3: tensor([0.0625, 0.1141, 0.1055, 0.7179])\n",
      "        \n",
      "3 -> 3\n",
      "goood\n",
      "\n",
      "        0: tensor([0.7516, 0.0135, 0.2096, 0.0253])\n",
      "        1: tensor([0.0098, 0.7308, 0.0053, 0.2540])\n",
      "        2: tensor([0.0676, 0.0013, 0.6626, 0.2685])\n",
      "        3: tensor([0.0464, 0.0688, 0.0660, 0.8188])\n",
      "        \n",
      "3 -> 1\n",
      "\n",
      "        0: tensor([0.6839, 0.0141, 0.2764, 0.0255])\n",
      "        1: tensor([0.0655, 0.6168, 0.0255, 0.2921])\n",
      "        2: tensor([0.0612, 0.0011, 0.6644, 0.2733])\n",
      "        3: tensor([0.0361, 0.0482, 0.0435, 0.8721])\n",
      "        \n",
      "3 -> 2\n",
      "\n",
      "        0: tensor([0.6855, 0.0154, 0.2766, 0.0225])\n",
      "        1: tensor([0.0109, 0.7586, 0.0038, 0.2266])\n",
      "        2: tensor([4.3794e-02, 6.5618e-04, 6.8705e-01, 2.6850e-01])\n",
      "        3: tensor([0.0364, 0.0386, 0.0402, 0.8849])\n",
      "        \n",
      "3 -> 3\n",
      "goood\n",
      "\n",
      "        0: tensor([0.6831, 0.0167, 0.2767, 0.0235])\n",
      "        1: tensor([0.0209, 0.7430, 0.0065, 0.2296])\n",
      "        2: tensor([3.6386e-02, 4.8092e-04, 7.0854e-01, 2.5459e-01])\n",
      "        3: tensor([0.0301, 0.0272, 0.0351, 0.9076])\n",
      "        \n",
      "3 -> 3\n",
      "goood\n"
     ]
    }
   ],
   "source": [
    "train_data = [3]*5\n",
    "\n",
    "for c in train_data:\n",
    "    m = get_move(c)\n",
    "    print(f\"{c} -> {m}\")\n",
    "    reward = False\n",
    "    if m == c:\n",
    "        print(f\"goood\")\n",
    "        reward = True\n",
    "    train(c, m, reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b93ad62e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: tensor([0.4234, 0.2938, 0.2003, 0.0825], grad_fn=<SqueezeBackward0>)\n",
      "1: tensor([0.4354, 0.2907, 0.2006, 0.0733], grad_fn=<SqueezeBackward0>)\n",
      "2: tensor([0.4323, 0.2916, 0.2005, 0.0755], grad_fn=<SqueezeBackward0>)\n",
      "3: tensor([0.4345, 0.2910, 0.2006, 0.0740], grad_fn=<SqueezeBackward0>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "0: {model(cmd_to_tensor(0))}\n",
    "1: {model(cmd_to_tensor(1))}\n",
    "2: {model(cmd_to_tensor(2))}\n",
    "3: {model(cmd_to_tensor(3))}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc9da90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
